{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF Sentiment Analysis",
      "provenance": [],
      "collapsed_sections": [
        "e17BWoOfytYT",
        "lnPgljJKzGHt",
        "2REMT5x_2jVr",
        "ru-UWlugdGkd",
        "v0diJmCgdSrU",
        "SGIU9usaXcCG",
        "zyiC-IzvcWUJ"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mturnell001/Amazon-Sentiment-Analysis-NLP/blob/master/TFIDF_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3dc477WiOqJ",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF - BAG OF WORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbo5ZURXRzkt",
        "colab_type": "text"
      },
      "source": [
        "Bag of words implementation for text analysis is analogous to dumping all the words in a document into a bag and then counting their frequency. One major limitation to this method is that nuance, or any meaning implied by phrases and idiomatic expressions, can be difficult to infer. Consider an example 2-star review, written in natural language with slightly negative sentiment:\n",
        "> *I can not say that I am very satisfied with this item. The best thing about it was the price. The quality is not so good, but the color is beautiful. It does not have all the bells and whistles, but I know it will get you by!*\n",
        "\n",
        "We can perform a rudimentary tokenization on the document:\n",
        ">*whistles, doesn't, know, so, not, best, quality, can't, beautiful, but, item, bells, good, color, say, very, price, satisfied*\n",
        "\n",
        "Given just the tokens, it is very difficult to intuitively reason whether the sentiment is positive or negative. How are we to know which words \"can't,\" \"doesn't,\" and \"not\" apply to? The phrase \"get you by\" has been lost to stopword removal. \n",
        "\n",
        "Here is a 4-star review in natural language using exactly the same words:\n",
        "\n",
        ">*I am satisfied with this item. About the quality: it was very good, but I know by the price you will not get all the bells and whistles. But the thing is, it does not have the best color, so I can not say it is that beautiful.*\n",
        "\n",
        "All the same words, but the sentiment is markedly different! By training a machine-learning model, however, we can predict sentiment with a fair amount of accuracy.\n",
        "\n",
        "After tokenizing all documents, we determine term frequency and inter-document frequency for each token. A token and tf-idf vector form a feature. The features of a test dataset are used to train various machine learning models to predict sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e17BWoOfytYT",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Data Fetching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-tg_saKFhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQtBTR5jJtTU",
        "colab_type": "code",
        "outputId": "201f6277-de02-4448-a744-d3546c34ef39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "#get data\n",
        "#https://www.kaggle.com/bittlingmayer/amazonreviews/version/7#\n",
        "!wget https://mt-proj-001.s3.us-east-2.amazonaws.com/train.csv\n",
        "!wget https://mt-proj-001.s3.us-east-2.amazonaws.com/test.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-21 05:20:55--  https://mt-proj-001.s3.us-east-2.amazonaws.com/train.csv\n",
            "Resolving mt-proj-001.s3.us-east-2.amazonaws.com (mt-proj-001.s3.us-east-2.amazonaws.com)... 52.219.88.128\n",
            "Connecting to mt-proj-001.s3.us-east-2.amazonaws.com (mt-proj-001.s3.us-east-2.amazonaws.com)|52.219.88.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1585200224 (1.5G) [text/csv]\n",
            "Saving to: ‘train.csv.2’\n",
            "\n",
            "train.csv.2         100%[===================>]   1.48G  75.9MB/s    in 21s     \n",
            "\n",
            "2020-03-21 05:21:16 (72.6 MB/s) - ‘train.csv.2’ saved [1585200224/1585200224]\n",
            "\n",
            "--2020-03-21 05:21:17--  https://mt-proj-001.s3.us-east-2.amazonaws.com/test.csv\n",
            "Resolving mt-proj-001.s3.us-east-2.amazonaws.com (mt-proj-001.s3.us-east-2.amazonaws.com)... 52.219.97.42\n",
            "Connecting to mt-proj-001.s3.us-east-2.amazonaws.com (mt-proj-001.s3.us-east-2.amazonaws.com)|52.219.97.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176046679 (168M) [text/csv]\n",
            "Saving to: ‘test.csv.1’\n",
            "\n",
            "test.csv.1          100%[===================>] 167.89M  66.1MB/s    in 2.5s    \n",
            "\n",
            "2020-03-21 05:21:20 (66.1 MB/s) - ‘test.csv.1’ saved [176046679/176046679]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnPgljJKzGHt",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTNTRCMsKF4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read into pandas DataFrames\n",
        "train_data = pd.read_csv('train.csv', names=['label', 'title', 'review'])\n",
        "test_data = pd.read_csv('test.csv', names = ['label', 'title', 'review'])\n",
        "label_names = ['negative', 'positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV4sLqqdjEkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ab8dfb9f-166f-4499-9eb0-8e3ba7368aa4"
      },
      "source": [
        "#check class balance ratio, its' 50/50\n",
        "train_data.label.value_counts()\n",
        "test_data.label.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    200000\n",
              "1    200000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAsz6sqMwdtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#necessary for logistic regression and random search below\n",
        "tf_idf_vectorizer = TfidfVectorizer()\n",
        "X_train_tf_idf = tf_idf_vectorizer.fit_transform(train_data.review)\n",
        "X_test_tf_idf = tf_idf_vectorizer.transform(test_data.review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQcFF0VcR1gw",
        "colab_type": "code",
        "outputId": "172c56ab-0bea-4c1e-c375-87a62f6dcf8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save this for use later\n",
        "vectorizer_filename = 'fitted_vectorizer.sav'\n",
        "joblib.dump(tf_idf_vectorizer, vectorizer_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fitted_vectorizer.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2REMT5x_2jVr",
        "colab_type": "text"
      },
      "source": [
        "## Model: LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzESQn5VH4ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "lr_classifier_model = LogisticRegression(solver='sag', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq8jI-d92ogL",
        "colab_type": "code",
        "outputId": "3cb6d19a-5049-469d-ecf5-3e6bae5cd355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#train model with train data\n",
        "lr_classifier_model.fit(X_train_tf_idf, train_data.label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U36fTq3M2osh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict with model, using test data\n",
        "lr_predicted = lr_classifier_model.predict(X_test_tf_idf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6rsTZyRXFx2",
        "colab_type": "code",
        "outputId": "84734b12-b6dc-479c-85c8-ba6843818c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "#view the results\n",
        "print(f'accuracy : {np.mean(lr_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , lr_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8893175\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.89      0.89    200000\n",
            "    positive       0.89      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-UWlugdGkd",
        "colab_type": "text"
      },
      "source": [
        "##Model: NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR4xa6TYXO6h",
        "colab_type": "code",
        "outputId": "a68ff821-baa2-40a7-ba85-1a594a425e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_classifier_model = Pipeline([('tfidf-vect', TfidfVectorizer()),\n",
        "                     ('clf', MultinomialNB())],\n",
        "                     verbose=True)\n",
        "nb_classifier_model.fit(train_data.review, train_data.label)\n",
        "nb_predicted = nb_classifier_model.predict(test_data.review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 2) Processing tfidf-vect, total= 3.6min\n",
            "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPahrOe6a2JE",
        "colab_type": "code",
        "outputId": "d6f7f152-67a1-486f-ccb9-1448658887a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "num_reviews = 0\n",
        "num_correct = 0\n",
        "for actual, prediction in zip(test_data.label, nb_predicted):\n",
        "  num_reviews += 1\n",
        "  if actual == prediction:\n",
        "    num_correct += 1\n",
        "print(f'accuracy: {num_correct/num_reviews} :: ({num_correct}/{num_reviews})''')\n",
        "print(metrics.classification_report(test_data.label, nb_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8256575 :: (330263/400000)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.81      0.84      0.83    200000\n",
            "    positive       0.84      0.81      0.82    200000\n",
            "\n",
            "    accuracy                           0.83    400000\n",
            "   macro avg       0.83      0.83      0.83    400000\n",
            "weighted avg       0.83      0.83      0.83    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0diJmCgdSrU",
        "colab_type": "text"
      },
      "source": [
        "## Model: SUPPORT VECTOR MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWHCJg3aKgO",
        "colab_type": "code",
        "outputId": "2f8d6a49-8e37-49e0-bc6c-69441417de99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "svm_classifier_model = Pipeline([('tfidf-vect', TfidfVectorizer()),\n",
        "                     ('clf', SGDClassifier(n_jobs=-1))],\n",
        "                     verbose=True)\n",
        "svm_classifier_model.fit(train_data.review, train_data.label)\n",
        "svm_predicted = svm_classifier_model.predict(test_data.review)\n",
        "print(f'accuracy : {np.mean(svm_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label, svm_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 2) Processing tfidf-vect, total= 3.7min\n",
            "[Pipeline] ............... (step 2 of 2) Processing clf, total=  25.8s\n",
            "accuracy : 0.8657075\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.87      0.87    200000\n",
            "    positive       0.87      0.86      0.87    200000\n",
            "\n",
            "    accuracy                           0.87    400000\n",
            "   macro avg       0.87      0.87      0.87    400000\n",
            "weighted avg       0.87      0.87      0.87    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGIU9usaXcCG",
        "colab_type": "text"
      },
      "source": [
        "## Model: LOGISTIC REGRESSION - *Manual Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALmA3yTi2onR",
        "colab_type": "code",
        "outputId": "b1e8e181-fa8a-4f63-e366-5f26d29aac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "lr_lbfgs_model = LogisticRegression(solver='lbfgs', tol=0.0005, verbose=2, n_jobs=-1)\n",
        "lr_lbfgs_model.fit(X_train_tf_idf, train_data.label)\n",
        "lr_lbfgs_predicted = lr_lbfgs_model.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(lr_lbfgs_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , lr_lbfgs_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8872875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.89      0.89    200000\n",
            "    positive       0.89      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPT7O1tNgMTf",
        "colab_type": "text"
      },
      "source": [
        "Pretty close to the other model in terms of accuracy. There's a faster way to get a better model: Randomized Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Q2vS-nK1ZO",
        "colab_type": "text"
      },
      "source": [
        "## **Note: Due to the size of the dataset a multi-core, high RAM runtime is recommended for executing the following cells**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyiC-IzvcWUJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: RANDOMIZED SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9_0rFu0dXH7",
        "colab_type": "code",
        "outputId": "98351ab9-a6cb-4d16-a1aa-4542adb3434a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "#with many params, use randomized search\n",
        "lr_model = LogisticRegression(n_jobs=-1)\n",
        "lr_params = dict(C=uniform(loc=0,scale=3),\n",
        "                 tol=loguniform(1e-5,1e-3),\n",
        "                 max_iter=uniform(loc=100,scale=400),\n",
        "                 solver=['sag', 'lbfgs'])\n",
        "lr_grid = RandomizedSearchCV(lr_model, lr_params,verbose=3, n_iter=10, n_jobs=8)\n",
        "lr_search = lr_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(lr_search.best_params_)\n",
        "print(lr_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed: 14.8min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed: 29.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1.8395120525238218, 'max_iter': 345.70124140013627, 'solver': 'sag', 'tol': 0.00015302782734043582}\n",
            "0.8886269444444445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFp6EUVoQ-xs",
        "colab_type": "code",
        "outputId": "88171f2c-7609-497e-c4ce-a78db1bc2eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "#make a slight tune to try to further increase accuracy\n",
        "ideal_lr_model = LogisticRegression(n_jobs=-1, C=1.48963, max_iter = 463, solver='sag', tol=0.00055)\n",
        "ideal_lr_model.fit(X_train_tf_idf, train_data.label)\n",
        "ideal_lr_predictions = ideal_lr_model.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(ideal_lr_predictions == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , ideal_lr_predictions, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8894325\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.89      0.89    200000\n",
            "    positive       0.89      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvSU4gxNe7gg",
        "colab_type": "code",
        "outputId": "b891494c-d30f-4e55-85ba-c5c8e9b66489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#this model performed even better! so we'll save it as our best log reg model\n",
        "lr_filename = 'top_lr_model.sav'\n",
        "joblib.dump(ideal_lr_model, lr_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['top_lr_model.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcZjDvKOH6W",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: GRID SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fBE1EmZCFw3",
        "colab_type": "code",
        "outputId": "b0a1819b-f855-4d0e-d1ac-fefd32dad07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#svm: alpha, tol, max_iter\n",
        "svm_model = SGDClassifier(n_jobs=-1, early_stopping=True)\n",
        "svm_params = dict(alpha=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3],\n",
        "               tol=[1e-4, 5e-3, 1e-3, 5e-2, 1e-2],\n",
        "               max_iter=[1000, 1500, 2000, 2500])\n",
        "svm_grid = GridSearchCV(estimator=svm_model, param_grid=svm_params, verbose=3, n_jobs=6)\n",
        "svm_search = svm_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_search.best_params_)\n",
        "print(svm_search.best_score_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed: 18.8min\n",
            "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed: 35.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1e-05, 'max_iter': 1000, 'tol': 0.0001}\n",
            "0.8827925000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVAiBRXvI3p7",
        "colab_type": "code",
        "outputId": "a13faeba-f543-414a-cbe5-10f3175a2cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "#try again with a slightly different grid\n",
        "svm_2_params=dict(alpha=[5e-5, 1e-5, 5e-4],\n",
        "                  tol=[1e-4, 5e-3, 1e-3],\n",
        "                  max_iter=[1000])\n",
        "svm_2_grid = GridSearchCV(estimator=svm_model, param_grid=svm_2_params, verbose=3, n_jobs=6)\n",
        "svm_2_search = svm_2_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_2_search.best_params_)\n",
        "print(svm_2_search.best_score_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  45 out of  45 | elapsed:  3.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1e-05, 'max_iter': 1000, 'tol': 0.005}\n",
            "0.8827677777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHRTzcLNv4af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "18dd728a-1754-47f2-935d-6e836aa79eb7"
      },
      "source": [
        "svm_2_predictions = svm_2_search.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(svm_2_predictions == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , svm_2_predictions, target_names=label_names))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8833375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.89      0.88    200000\n",
            "    positive       0.89      0.88      0.88    200000\n",
            "\n",
            "    accuracy                           0.88    400000\n",
            "   macro avg       0.88      0.88      0.88    400000\n",
            "weighted avg       0.88      0.88      0.88    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhPwNEOHnE8_",
        "colab_type": "code",
        "outputId": "b94c87a7-12c7-4196-bde0-31cf11c62857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save this model as it is the best perfroming svm model\n",
        "svm_grid_model_fn = 'top_svm_model.sav'\n",
        "joblib.dump(svm_2_search, svm_grid_model_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ideal_svm_grid.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WDMQH-WvLJa",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: RANDOMIZED SEARCH - *SGDClassifier*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koMClmC5lpxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "a8360bbd-8889-497d-8485-7454c4d336b8"
      },
      "source": [
        "svm_rand_model = SGDClassifier(n_jobs=-1, early_stopping=True)\n",
        "svm_rand_params = dict(alpha=loguniform(1e-7,1e-3),\n",
        "                 tol=loguniform(1e-5,1e-1),\n",
        "                 max_iter=uniform(loc=1250,scale=1750),\n",
        "                 )\n",
        "svm_rand_grid = RandomizedSearchCV(svm_rand_model, svm_rand_params, n_iter=10, n_jobs=1)\n",
        "svm_rand_search = svm_rand_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_rand_search.best_params_)\n",
        "svm_rand_predictions = svm_rand_search.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(svm_rand_predictions == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , svm_rand_predictions, target_names=label_names))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1.2296857264134206e-06, 'max_iter': 2150.1092370333977, 'tol': 0.0002860922160221194}\n",
            "accuracy : 0.88794\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.88      0.89    200000\n",
            "    positive       0.88      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo0UNaTHrOct",
        "colab_type": "text"
      },
      "source": [
        "This model did not have higher performance than the one produced by grid search, which is understandable as it does not test all possible models, only a randomly selected subset of them."
      ]
    }
  ]
}